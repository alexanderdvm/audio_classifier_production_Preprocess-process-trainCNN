# ğŸ« Sistema de ClasificaciÃ³n de Enfermedades Respiratorias mediante CNN

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.8%2B-orange.svg)](https://www.tensorflow.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Production-success.svg)]()

Sistema de clasificaciÃ³n automÃ¡tica de enfermedades respiratorias mediante anÃ¡lisis de audio utilizando **Redes Neuronales Convolucionales (CNN)** con extracciÃ³n de caracterÃ­sticas espectrales (Mel Spectrograms y MFCC).

---

## ğŸ“‹ Tabla de Contenidos

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Arquitectura del Sistema](#-arquitectura-del-sistema)
- [TecnologÃ­as](#-tecnologÃ­as)
- [Requisitos](#-requisitos)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso](#-uso)
- [Pipeline de Entrenamiento](#-pipeline-de-entrenamiento)
- [Resultados](#-resultados)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [ContribuciÃ³n](#-contribuciÃ³n)
- [Licencia](#-licencia)
- [Contacto](#-contacto)

---

## âœ¨ CaracterÃ­sticas

- ğŸµ **Preprocesamiento automÃ¡tico** de audios a duraciÃ³n fija (10 segundos)
- ğŸ”„ **Data augmentation avanzado** con 8 transformaciones para balanceo de clases
- ğŸ“Š **ExtracciÃ³n de caracterÃ­sticas espectrales**:
  - Mel Spectrograms (40 bandas)
  - MFCC (40 coeficientes)
  - ConcatenaciÃ³n de ambas
- ğŸ§  **CNN optimizada** con 4 bloques convolucionales + BatchNormalization + Dropout
- ğŸ“ˆ **ValidaciÃ³n cruzada estratificada** (K-Folds = 5)
- ğŸ’¾ **Sistema de cachÃ©** para optimizar procesamiento
- ğŸ¯ **MÃ©tricas completas**: Accuracy, F1-Score, Precision, Recall
- ğŸ“‰ **Visualizaciones**: Matrices de confusiÃ³n, curvas de aprendizaje, comparativas

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PIPELINE COMPLETO                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   1. NORMALIZACIÃ“N DE AUDIOS    â”‚
        â”‚   â€¢ DuraciÃ³n fija: 10 segundos  â”‚
        â”‚   â€¢ SegmentaciÃ³n automÃ¡tica     â”‚
        â”‚   â€¢ Sample Rate: 4000 Hz        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   2. DATA AUGMENTATION          â”‚
        â”‚   â€¢ Balanceo de clases          â”‚
        â”‚   â€¢ 8 transformaciones          â”‚
        â”‚   â€¢ Target: 1778 samples/clase  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   3. EXTRACCIÃ“N CARACTERÃSTICAS â”‚
        â”‚   â€¢ MFCC (40 coeficientes)      â”‚
        â”‚   â€¢ Mel Spectrogram (40 bandas) â”‚
        â”‚   â€¢ ConcatenaciÃ³n (MFCC+Mel)    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   4. ENTRENAMIENTO CNN          â”‚
        â”‚   â€¢ K-Fold CV (k=5)             â”‚
        â”‚   â€¢ 3 tipos de features         â”‚
        â”‚   â€¢ Early stopping + ReduceLR   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   5. EVALUACIÃ“N Y MÃ‰TRICAS      â”‚
        â”‚   â€¢ Accuracy, F1, Precision     â”‚
        â”‚   â€¢ Confusion Matrix            â”‚
        â”‚   â€¢ ComparaciÃ³n de features     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Arquitectura CNN

```
INPUT (40x157x1 o 80x157x1)
    â”‚
    â”œâ”€ Conv2D(16, 3Ã—3) + BatchNorm + MaxPool + Dropout(0.25)
    â”‚
    â”œâ”€ Conv2D(32, 3Ã—3) + BatchNorm + MaxPool + Dropout(0.25)
    â”‚
    â”œâ”€ Conv2D(64, 3Ã—3) + BatchNorm + MaxPool + Dropout(0.25)
    â”‚
    â”œâ”€ Conv2D(128, 3Ã—3) + BatchNorm + MaxPool + Dropout(0.25)
    â”‚
    â”œâ”€ GlobalAveragePooling2D
    â”‚
    â”œâ”€ Dense(128, ReLU) + Dropout(0.25)
    â”‚
    â””â”€ Dense(N_CLASES, Softmax)
```

---

## ğŸ› ï¸ TecnologÃ­as

### Core
- **Python** 3.8+
- **TensorFlow/Keras** 2.8+ - Deep Learning
- **Librosa** - Procesamiento de audio
- **Scikit-learn** - Machine Learning utilities

### Procesamiento & VisualizaciÃ³n
- **NumPy** - Operaciones numÃ©ricas
- **Pandas** - ManipulaciÃ³n de datos
- **Matplotlib** - Visualizaciones
- **Seaborn** - GrÃ¡ficos estadÃ­sticos
- **SciPy** - Procesamiento de seÃ±ales

---

## ğŸ’» Requisitos

### Hardware Recomendado

```
CPU: Intel i5/AMD Ryzen 5 o superior (4+ cores)
RAM: 16 GB mÃ­nimo (32 GB recomendado)
GPU: NVIDIA con CUDA 11.x (opcional)
     â€¢ 4+ GB VRAM mÃ­nimo
     â€¢ 8+ GB VRAM recomendado
Almacenamiento: 50+ GB libres
```

### Software

```
Python: 3.8 o superior
CUDA: 11.x (si se usa GPU)
cuDNN: Compatible con TensorFlow
```

---

## ğŸ“¦ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/respiratory-cnn-classifier.git
cd respiratory-cnn-classifier
```

### 2. Crear entorno virtual

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### 3. Instalar dependencias

```bash
# OpciÃ³n 1: Con requirements.txt
pip install -r requirements.txt

# OpciÃ³n 2: InstalaciÃ³n manual
pip install librosa soundfile
pip install tensorflow scikit-learn
pip install numpy pandas matplotlib seaborn
pip install tqdm scipy

# Para GPU (NVIDIA)
pip install tensorflow-gpu
```

### 4. Verificar instalaciÃ³n

```bash
python -c "import tensorflow as tf; print('TensorFlow:', tf.__version__)"
python -c "import librosa; print('Librosa:', librosa.__version__)"
```

---

## ğŸš€ Uso

### Pipeline Completo

#### **Paso 1: NormalizaciÃ³n de Audios**

```bash
python src/normalize_audio.py
```

**ConfiguraciÃ³n** (`normalize_audio.py`):
```python
input_folder = "ruta/a/audios/originales"
output_folder = "ruta/a/audios/normalizados"
target_sec = 10  # DuraciÃ³n objetivo en segundos
```

**Salida**:
- Audios segmentados a 10 segundos
- Archivo CSV con mapeo de archivos

---

#### **Paso 2: Data Augmentation**

```bash
python src/data_augmentation.py
```

**ConfiguraciÃ³n** (`data_augmentation.py`):
```python
SRC_ROOT = "ruta/a/audios/normalizados"
DST_ROOT = "ruta/a/audios/aumentados"
num_target_per_class = 1778  # Objetivo por clase
sr = 4000  # Sample rate
```

**Transformaciones aplicadas**:
- âœ… White Noise (SNR: 10-30 dB)
- âœ… Time Shift (Â±1.5 segundos)
- âœ… Time Stretch (0.9-1.1x)
- âœ… Pitch Shift (Â±2 semitonos)
- âœ… Volume Change (Â±8 dB)
- âœ… Lowpass Filter (300-3000 Hz)
- âœ… Highpass Filter (20-300 Hz)
- âœ… Crop/Pad aleatorio

---

#### **Paso 3: Entrenamiento**

```bash
python src/train_cnn.py
```

**ConfiguraciÃ³n** (`train_cnn.py`):
```python
DATA_DIR = "ruta/a/audios/aumentados"
OUTPUT_ROOT = "ruta/a/resultados"

# HiperparÃ¡metros
N_FOLDS = 5          # K-Fold Cross-Validation
EPOCHS = 60          # Ã‰pocas mÃ¡ximas
BATCH_SIZE = 32      # TamaÃ±o de batch
LEARNING_RATE = 1e-3 # Learning rate
DROPOUT = 0.25       # Ratio de dropout
```

**Features extraÃ­das**:
- `mfcc`: 40 coeficientes MFCC
- `mel`: 40 bandas Mel Spectrogram
- `concat`: ConcatenaciÃ³n MFCC + Mel

---

### Ejemplo RÃ¡pido

```bash
# 1. Normalizar audios
python src/normalize_audio.py

# 2. Aumentar dataset
python src/data_augmentation.py

# 3. Entrenar modelos
python src/train_cnn.py

# Los resultados estarÃ¡n en OUTPUT_ROOT/
```

---

## ğŸ“Š Pipeline de Entrenamiento

### 1. Preprocesamiento

```python
# NormalizaciÃ³n de audios a 10 segundos
Audio original (35s) â†’ [Seg1 (10s), Seg2 (10s), Seg3 (10s), Seg4 (10s)]

# Si Ãºltimo segmento < 10s: padding circular
Audio (15s) â†’ [Seg1 (10s), Seg2 (5s + 5s del inicio)]
```

### 2. Data Augmentation

```python
# Balanceo de clases
Clase A: 500 audios  â†’ Copiar + Generar 1278 aumentados = 1778
Clase B: 2000 audios â†’ Seleccionar 1778 aleatorios = 1778
Clase C: 1200 audios â†’ Copiar + Generar 578 aumentados = 1778
```

### 3. ExtracciÃ³n de Features

```python
# Por cada audio (10s @ 4000 Hz)
MFCC:   (40, 157) â†’ 40 coeficientes Ã— 157 frames
Mel:    (40, 157) â†’ 40 bandas Ã— 157 frames
Concat: (80, 157) â†’ CombinaciÃ³n de ambos
```

### 4. Entrenamiento K-Fold

```python
# 5-Fold Cross-Validation
Dataset (95%) â†’ Split en 5 partes
    Fold 1: Train[2,3,4,5] | Val[1] â†’ Modelo_1
    Fold 2: Train[1,3,4,5] | Val[2] â†’ Modelo_2
    Fold 3: Train[1,2,4,5] | Val[3] â†’ Modelo_3
    Fold 4: Train[1,2,3,5] | Val[4] â†’ Modelo_4
    Fold 5: Train[1,2,3,4] | Val[5] â†’ Modelo_5

Test Web (5%) â†’ Apartado para evaluaciÃ³n final
```

### 5. Callbacks

```python
ModelCheckpoint  â†’ Guarda mejor modelo por fold
EarlyStopping    â†’ Detiene si no mejora en 10 Ã©pocas
ReduceLROnPlateau â†’ Reduce LR si no mejora en 5 Ã©pocas
```

---

## ğŸ“ˆ Resultados

### MÃ©tricas por Feature Type

```
=== RESUMEN FINAL ===
Feature    | Mean Accuracy | Std     | Mean F1 | Std
-----------|---------------|---------|---------|--------
MFCC       | 87.45%       | Â±1.23%  | 0.8621  | Â±0.015
Mel        | 89.12%       | Â±0.98%  | 0.8834  | Â±0.012
Concat     | 92.34%       | Â±0.87%  | 0.9145  | Â±0.009
```

### Outputs Generados

```
OUTPUT_ROOT/
â”‚
â”œâ”€ mfcc/
â”‚   â”œâ”€ models/              # Modelos entrenados (.h5)
â”‚   â”œâ”€ reports/             # Reportes de clasificaciÃ³n (.json)
â”‚   â”œâ”€ histories/           # Historiales de entrenamiento (.csv)
â”‚   â”œâ”€ confusion_matrices/  # Matrices de confusiÃ³n (.png)
â”‚   â”œâ”€ learning_curves/     # Curvas de aprendizaje (.png)
â”‚   â”œâ”€ fold_metrics.csv     # MÃ©tricas por fold
â”‚   â””â”€ summary.json         # Resumen de resultados
â”‚
â”œâ”€ mel/                     # (misma estructura)
â”œâ”€ concat/                  # (misma estructura)
â”‚
â”œâ”€ test_web/                # 5% audios para producciÃ³n
â”‚   â”œâ”€ clase1/
â”‚   â”œâ”€ clase2/
â”‚   â””â”€ ...
â”‚
â”œâ”€ comparison_summary.csv                           # ComparaciÃ³n final
â”œâ”€ results_summary_all.json                         # Todos los resultados
â””â”€ feature_mean_comparison_mfcc_mel_concat.png     # GrÃ¡fico comparativo
```

---

## ğŸ“ Estructura del Proyecto

```
respiratory-cnn-classifier/
â”‚
â”œâ”€ src/
â”‚   â”œâ”€ normalize_audio.py          # NormalizaciÃ³n de audios
â”‚   â”œâ”€ data_augmentation.py        # Aumento de datos
â”‚   â””â”€ train_cnn.py                # Entrenamiento CNN
â”‚
â”œâ”€ models/                          # Modelos entrenados
â”‚   â”œâ”€ mfcc_best.h5
â”‚   â”œâ”€ mel_best.h5
â”‚   â””â”€ concat_best.h5
â”‚
â”œâ”€ data/
â”‚   â”œâ”€ raw/                        # Audios originales
â”‚   â”œâ”€ normalized/                 # Audios normalizados
â”‚   â”œâ”€ augmented/                  # Audios aumentados
â”‚   â””â”€ test_web/                   # Test set (5%)
â”‚
â”œâ”€ notebooks/                      # Jupyter notebooks
â”‚   â”œâ”€ exploratory_analysis.ipynb
â”‚   â””â”€ model_evaluation.ipynb
â”‚
â”œâ”€ docs/                           # DocumentaciÃ³n
â”‚   â”œâ”€ architecture.md
â”‚   â””â”€ preprocessing.md
â”‚
â”œâ”€ results/                        # Resultados de entrenamiento
â”‚   â”œâ”€ mfcc/
â”‚   â”œâ”€ mel/
â”‚   â””â”€ concat/
â”‚
â”œâ”€ requirements.txt                # Dependencias
â”œâ”€ README.md                       # Este archivo
â”œâ”€ LICENSE                         # Licencia
â””â”€ .gitignore                      # Archivos ignorados
```

---

## ğŸ¤ ContribuciÃ³n

Â¡Las contribuciones son bienvenidas! Si deseas contribuir:

1. **Fork** el proyecto
2. Crea una **rama** para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. **Commit** tus cambios (`git commit -m 'AÃ±adir nueva funcionalidad'`)
4. **Push** a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un **Pull Request**

### Ãreas de mejora

- [ ] Implementar modelos adicionales (ResNet, EfficientNet)
- [ ] AÃ±adir mÃ¡s transformaciones de augmentation
- [ ] Optimizar hiperparÃ¡metros con Optuna
- [ ] Implementar pruning y quantization
- [ ] Crear API REST para inferencia
- [ ] Desarrollar interfaz web

---

## ğŸ› Troubleshooting

### Error: Out of Memory (OOM)

```python
# SoluciÃ³n 1: Reducir batch size
BATCH_SIZE = 16  # o menor

# SoluciÃ³n 2: Dividir features en mÃ¡s partes
N_PARTS = 4

# SoluciÃ³n 3: Activar memory growth
tf.config.experimental.set_memory_growth(gpu, True)
```

### Error: CachÃ© corrupto

```bash
# Eliminar cachÃ© y regenerar
rm -rf feature_cache/
python src/train_cnn.py
```

### Warning: GPU no detectada

```bash
# Verificar instalaciÃ³n de CUDA
nvidia-smi

# Verificar TensorFlow detecta GPU
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"

# Reinstalar TensorFlow GPU
pip uninstall tensorflow
pip install tensorflow-gpu
```

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ“§ Contacto

**Autor**: Tu Nombre  
**Email**: tu.email@ejemplo.com  
**LinkedIn**: [tu-perfil](https://linkedin.com/in/tu-perfil)  
**GitHub**: [@tu-usuario](https://github.com/tu-usuario)

---

## ğŸ™ Agradecimientos

- Dataset de enfermedades respiratorias
- Librosa por las herramientas de procesamiento de audio
- TensorFlow/Keras por el framework de Deep Learning
- Comunidad de cÃ³digo abierto

---

## ğŸ“š Referencias

1. [Librosa Documentation](https://librosa.org/doc/latest/index.html)
2. [TensorFlow Audio Recognition](https://www.tensorflow.org/tutorials/audio/simple_audio)
3. [CNN for Audio Classification](https://arxiv.org/abs/1610.00087)
4. [MFCC Feature Extraction](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum)

---

## ğŸ”„ Historial de Versiones

- **v1.0.0** (2025-01-XX)
  - âœ… ImplementaciÃ³n inicial del sistema
  - âœ… Preprocesamiento y data augmentation
  - âœ… Entrenamiento CNN con 3 tipos de features
  - âœ… K-Fold Cross-Validation
  - âœ… Sistema de cachÃ© optimizado

---

<div align="center">

**â­ Si este proyecto te fue Ãºtil, considera darle una estrella â­**

Made with â¤ï¸ and ğŸ Python

</div>
